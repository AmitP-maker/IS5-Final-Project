{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Assignment 2\n\nVariable `data` shows where data is located. Modify it as needed"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "data = \"gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/\""}, {"cell_type": "markdown", "metadata": {"jp-MarkdownHeadingCollapsed": true, "tags": []}, "source": "## Data\n\nThis is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016. The data was taken from Kaggle. The `athlete_events` Dataset contains $271,116$ rows and $15$ columns and the NOC region dataset contains $230$ rows and $3$ columns. They will be merged together by the National Olympic Committee (NOC) region. Both files are comma separated.\n\n**Source:**\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, athlete_events, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#athlete_events.csv\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, noc_regions, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#noc_regions.csv\n\n**ATTRIBUTES:**\n\n**athlete_events.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:----:|:----:|:----|\n| ID |  integer | Unique number for each athlete |\n| Name | string | Athlete\u2019s name |\n| Sex | string | M or F |\n| Age | integer |  |\n| Height | integer | In centimeters |\n| Weight | integer | In kilograms |\n| Team | string | Team name |\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Games | string | Year and season |\n| Year | integer |  |\n| Season | string | Summer or Winter |\n| City | string | Host city |\n| Sport | string |  |\n| Event | string |  |\n| Medal | string | Gold, Silver, Bronze, or NA |\n\n**noc_regions.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:--|--|:--|\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Region | string |  |\n| notes | string |  |"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## Upload the data into Google Cloud Storage\n\nUse the paths above to download our two files and upload them to your Google bucket. For consistency use the following path:\n\n`gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis`\n\nand upload the files into *olympics-analysis* directory.\n\nConfirm that files were uploaded successfully and are accessible via the notebook by the following gsutil command:"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/athlete_events.csv\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/athlete_events_del.csv\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/athlete_events_new.csv\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\n"}], "source": "!gsutil ls {data}"}, {"cell_type": "markdown", "metadata": {}, "source": "## Load the data into Spark\n\nAs seen in the [class notes](https://github.com/soltaniehha/Big-Data-Analytics-for-Business/blob/master/05-Basic-DF-Operations/01-Basic-Structured-Operations.ipynb) we can either ask Spark to infer the schema or we explicitely specify it ourselves. For this example we need to specify the schema explicitely since not all the columns will be converted the way we would like to by the default option.\n\nAs a reminder, here is how we can define a schema contained of two columns, one string and one integer:\n\n```python\nfrom pyspark.sql.types import StructField, StructType, StringType, LongType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"name\", StringType(), True)\n])\n\ndf = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(\"gs/path/to/file\")\n```\n\nModify this code to load athlete_events.csv. Call this DataFrame `athlete_events`:\n\n**Note:** We have \"NA\" values in our data. This could cause issues when loading the data. To overcome this we need to let Spark know that what string is representing `null` in the data. We can use the option/parameter `nullValue` (as used in the sample code above) and set it to \"NA\"."}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"Name\", StringType(), True),\n  StructField(\"Sex\", StringType(), True),\n  StructField(\"Age\", LongType(), True),\n  StructField(\"Height\", LongType(), True),\n  StructField(\"Weight\", LongType(), True),\n  StructField(\"Team\", StringType(), True),\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Games\", StringType(), True),\n  StructField(\"Year\", LongType(), True),\n  StructField(\"Season\", StringType(), True),\n  StructField(\"City\", StringType(), True),\n  StructField(\"Sport\", StringType(), True),\n  StructField(\"Event\", StringType(), True),\n  StructField(\"Medal\", StringType(), True)\n])"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the schema of this DataFrame:"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "271116"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql.functions import avg, col,sum,count\n\n\nathlete_events = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(data+\"athlete_events_new.csv\")\n\nathlete_events.count()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- ID: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: long (nullable = true)\n |-- Height: long (nullable = true)\n |-- Weight: long (nullable = true)\n |-- Team: string (nullable = true)\n |-- NOC: string (nullable = true)\n |-- Games: string (nullable = true)\n |-- Year: long (nullable = true)\n |-- Season: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Sport: string (nullable = true)\n |-- Event: string (nullable = true)\n |-- Medal: string (nullable = true)\n\n"}], "source": "# Your answer goes here\nathlete_events.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the first 5 rows:"}, {"cell_type": "code", "execution_count": 26, "metadata": {}, "outputs": [{"data": {"text/plain": "[Row(ID=1, Name='A Dijiang', Sex='M', Age=24, Height=180, Weight=80, Team='China', NOC='CHN', Games='1992 Summer', Year=1992, Season='Summer', City='Barcelona', Sport='Basketball', Event=\"Basketball Men's Basketball\", Medal=None),\n Row(ID=2, Name='A Lamusi', Sex='M', Age=23, Height=170, Weight=60, Team='China', NOC='CHN', Games='2012 Summer', Year=2012, Season='Summer', City='London', Sport='Judo', Event=\"Judo Men's Extra-Lightweight\", Medal=None),\n Row(ID=3, Name='Gunnar Nielsen Aaby', Sex='M', Age=24, Height=None, Weight=None, Team='Denmark', NOC='DEN', Games='1920 Summer', Year=1920, Season='Summer', City='Antwerpen', Sport='Football', Event=\"Football Men's Football\", Medal=None),\n Row(ID=4, Name='Edgar Lindenau Aabye', Sex='M', Age=34, Height=None, Weight=None, Team='Denmark/Sweden', NOC='DEN', Games='1900 Summer', Year=1900, Season='Summer', City='Paris', Sport='Tug-Of-War', Event=\"Tug-Of-War Men's Tug-Of-War\", Medal='Gold'),\n Row(ID=5, Name='Christine Jacoba Aaftink', Sex='F', Age=21, Height=185, Weight=82, Team='Netherlands', NOC='NED', Games='1988 Winter', Year=1988, Season='Winter', City='Calgary', Sport='Speed Skating', Event=\"Speed Skating Women's 500 metres\", Medal=None)]"}, "execution_count": 26, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.head(5)"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"data": {"text/plain": "['ID',\n 'Name',\n 'Sex',\n 'Age',\n 'Height',\n 'Weight',\n 'Team',\n 'NOC',\n 'Games',\n 'Year',\n 'Season',\n 'City',\n 'Sport',\n 'Event',\n 'Medal']"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.columns"}, {"cell_type": "markdown", "metadata": {}, "source": "We won't use the following columns, let's drop them from the DataFrame in a persistent way:\n\n* ID\n* Games\n* Event"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": "athlete_events = athlete_events.drop(\"ID\",\"Games\",\"Event\")"}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 4:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n|                Name|Sex|Age|Height|Weight|          Team|NOC|Year|Season|     City|        Sport|Medal|\n+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\n|           A Dijiang|  M| 24|   180|    80|         China|CHN|1992|Summer|Barcelona|   Basketball| null|\n|            A Lamusi|  M| 23|   170|    60|         China|CHN|2012|Summer|   London|         Judo| null|\n| Gunnar Nielsen Aaby|  M| 24|  null|  null|       Denmark|DEN|1920|Summer|Antwerpen|     Football| null|\n|Edgar Lindenau Aabye|  M| 34|  null|  null|Denmark/Sweden|DEN|1900|Summer|    Paris|   Tug-Of-War| Gold|\n|Christine Jacoba ...|  F| 21|   185|    82|   Netherlands|NED|1988|Winter|  Calgary|Speed Skating| null|\n+--------------------+---+---+------+------+--------------+---+----+------+---------+-------------+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "athlete_events.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": " Now load noc_regions.csv. Call this DataFrame `noc_regions`:"}, {"cell_type": "code", "execution_count": 10, "metadata": {}, "outputs": [], "source": "regionSchema = StructType([\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Region\", StringType(), True),\n  StructField(\"Notes\", StringType(), True)\n])\n\nnoc_regions = spark.read.format(\"csv\")\\\n  .schema(regionSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(data + \"noc_regions.csv\")\n"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----------+--------------------+\n|NOC|     Region|               Notes|\n+---+-----------+--------------------+\n|AFG|Afghanistan|                null|\n|AHO|    Curacao|Netherlands Antilles|\n|ALB|    Albania|                null|\n|ALG|    Algeria|                null|\n|AND|    Andorra|                null|\n|ANG|     Angola|                null|\n|ANT|    Antigua| Antigua and Barbuda|\n|ANZ|  Australia|         Australasia|\n+---+-----------+--------------------+\nonly showing top 8 rows\n\n"}], "source": "noc_regions.show(8)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Caching\n\nSince we will be using these two DataFrames a lot in this notebook let's `cache()` them to speed up our execution. Caching allows the DataFrame to be loaded and persist in the memory. If we don't use this option, every time we execute an action our DataFrame gets loaded from our Cloud Storage, which is not ideal and will add to our execution time:\n\n**Note:** Caching is a lazy transformation. It will happen the first time you execute an action against the DataFrame, not when you cache that DataFrame."}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[Name: string, Sex: string, Age: bigint, Height: bigint, Weight: bigint, Team: string, NOC: string, Year: bigint, Season: string, City: string, Sport: string, Medal: string]"}, "execution_count": 12, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.cache()"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[NOC: string, Region: string, Notes: string]"}, "execution_count": 13, "metadata": {}, "output_type": "execute_result"}], "source": "noc_regions.cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 1\n\nWhat is the minimum and maximum `year`?"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 6:=============================>                             (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+---------+\n|min(Year)|max(Year)|\n+---------+---------+\n|     1896|     2016|\n+---------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql.functions import min, max\nathlete_events.select(min(\"Year\"), max(\"Year\")).show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 2\n\nIs the following statement True or False?\n\n> Averag age of female athletes who attended the olympic games after 1990 has raised when compared to the era before then."}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------------+\n|avg_female_age_before_1990|\n+--------------------------+\n|        22.034368070953438|\n+--------------------------+\n\n+-------------------------+\n|avg_female_age_after_1990|\n+-------------------------+\n|       24.619499568593614|\n+-------------------------+\n\n"}], "source": "from pyspark.sql.functions import avg, col\n\nathlete_events.where(athlete_events[\"Sex\"] == \"F\").where(\"Year < 1990\")\\\n  .select(avg(col(\"Age\")).alias(\"avg_female_age_before_1990\")).show()\n\nathlete_events.where(athlete_events[\"Sex\"] == \"F\").where(\"Year >= 1990\")\\\n  .select(avg(col(\"Age\")).alias(\"avg_female_age_after_1990\")).show()"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "True\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 3\n\nHow many Gold medals were given to men from 1970 to 2000 (including both years)?"}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "3186"}, "execution_count": 16, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql.functions import sum, count\n\n\n#athlete_events\\\n#    .where(athlete_events[\"sex\"] == \"M\")\\\n#    .where(col(\"year\") >= 1970)\\\n#    .where(col(\"year\") <= 2000)\\\n#    .where(col(\"medal\") == \"Gold\")\\\n#    .count()\n\nathlete_events\\\n    .where(athlete_events[\"Year\"].between(1970,2000))\\\n    .where(col(\"Medal\") == \"Gold\")\\\n    .where(athlete_events[\"Sex\"] == \"M\")\\\n    .count()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 4\n\nHow many NOCs attended Summer Olympics 2016 in Rio de Janeiro?\n\nNOC stands for National Olympic Committee. Almost equivalent to a country."}, {"cell_type": "code", "execution_count": 17, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "207"}, "execution_count": 17, "metadata": {}, "output_type": "execute_result"}], "source": "# Your answer goes here\n\n# Your answer goes here\n#athlete_events\\\n#    .where(col(\"year\") == 2016)\\\n#    .where(col(\"Season\") == \"Summer\")\\\n#    .select(\"NOC\").distinct().count()\n\nathlete_events\\\n    .where(col(\"Games\") == \"2016 Summer\")\\\n    .select(\"NOC\").distinct().count()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 5\n\nCreate two DataFrames, one for the Winter games and one for the Summer games; these DataFrames should include a list of all NOCs that have wone gold medals in the colympics, and their count. Sort these DataFrame by the count in a descending order. Call these DataFrames `winter_gold_count` and `summer_gold_count` respectively. Using these two, answer the following questions:\n\nWhich country has the highest gold medal count in the Winter Olympics? How about the Summer Olympics?"}, {"cell_type": "code", "execution_count": 71, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|USA| 2376|\n|URS|  832|\n|GBR|  635|\n|GER|  591|\n|ITA|  518|\n+---+-----+\nonly showing top 5 rows\n\n+---+-----+\n|NOC|count|\n+---+-----+\n|CAN|  305|\n|URS|  249|\n|USA|  159|\n|GER|  153|\n|NOR|  151|\n+---+-----+\nonly showing top 5 rows\n\n"}], "source": "# Your answer goes here\nfrom pyspark.sql.functions import desc, col, expr, desc\n\nsummer_gold_count = athlete_events.select(\"NOC\").where(col(\"Season\") == \"Summer\").where(col(\"Medal\") == \"Gold\")\n\nwinter_gold_count = athlete_events.select(\"NOC\").where(col(\"Season\") == \"Winter\").where(col(\"Medal\") == \"Gold\")\n\n\nsummer_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(5)\n\nwinter_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Winter_Gold_Count\")\\\n    .sort(col(\"Winter_Gold_Count.count\").desc())\\\n    .show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 6\n\nUsing the common field `NOC`, merge `summer_gold_count` and `noc_regions` DataFrames.\n\nWhich region takes the 10th place? This is based on the number of gold medals in all of the Summer Olympics in our dataset."}, {"cell_type": "code", "execution_count": 72, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+-----+\n|   Region|count|\n+---------+-----+\n|      USA| 2376|\n|   Russia| 1220|\n|  Germany| 1074|\n|       UK|  635|\n|    Italy|  518|\n|   France|  465|\n|  Hungary|  432|\n|Australia|  362|\n|   Sweden|  352|\n|    China|  335|\n+---------+-----+\nonly showing top 10 rows\n\n"}], "source": "# Your answer goes here\njoinExpression = summer_gold_count[\"NOC\"] == noc_regions[\"NOC\"]\n\n#summer_gold_count\\\n#    .join(noc_regions, on=\"NOC\")\\\n#    .show(4)\n\nsummer_gold_count\\\n    .join(noc_regions, on=\"NOC\")\\\n    .groupby(\"Region\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(10)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# China (Region) is in 10th position with 335 medals."}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 4}