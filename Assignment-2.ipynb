{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Assignment 2\n\nVariable `data` shows where data is located. Modify it as needed"}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": "data = \"gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/\""}, {"cell_type": "markdown", "metadata": {"jp-MarkdownHeadingCollapsed": true, "tags": []}, "source": "## Data\n\nThis is a historical dataset on the modern Olympic Games, including all the Games from Athens 1896 to Rio 2016. The data was taken from Kaggle. The `athlete_events` Dataset contains $271,116$ rows and $15$ columns and the NOC region dataset contains $230$ rows and $3$ columns. They will be merged together by the National Olympic Committee (NOC) region. Both files are comma separated.\n\n**Source:**\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, athlete_events, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#athlete_events.csv\n\nGriffin, R, H (2018) 120 years of Olympic history: athletes and results, noc_regions, Found at: https://www.kaggle.com/heesoo37/120-years-of-olympic-history-athletes-and-results#noc_regions.csv\n\n**ATTRIBUTES:**\n\n**athlete_events.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:----:|:----:|:----|\n| ID |  integer | Unique number for each athlete |\n| Name | string | Athlete\u2019s name |\n| Sex | string | M or F |\n| Age | integer |  |\n| Height | integer | In centimeters |\n| Weight | integer | In kilograms |\n| Team | string | Team name |\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Games | string | Year and season |\n| Year | integer |  |\n| Season | string | Summer or Winter |\n| City | string | Host city |\n| Sport | string |  |\n| Event | string |  |\n| Medal | string | Gold, Silver, Bronze, or NA |\n\n**noc_regions.csv**\n\n| Column Name | Data Type | Description/Notes |\n|:--|--|:--|\n| NOC | string | National Olympic Committee, 3 letter code (Matches with `NOC` from noc_regions.csv) |\n| Region | string |  |\n| notes | string |  |"}, {"cell_type": "markdown", "metadata": {"tags": []}, "source": "## Upload the data into Google Cloud Storage\n\nUse the paths above to download our two files and upload them to your Google bucket. For consistency use the following path:\n\n`gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis`\n\nand upload the files into *olympics-analysis* directory.\n\nConfirm that files were uploaded successfully and are accessible via the notebook by the following gsutil command:"}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "gs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/athlete_events_new.csv\ngs://is-843-avp-01/notebooks/jupyter/data/olympics-analysis/noc_regions.csv\n"}], "source": "!gsutil ls {data}"}, {"cell_type": "markdown", "metadata": {}, "source": "## Load the data into Spark\n\nAs seen in the [class notes](https://github.com/soltaniehha/Big-Data-Analytics-for-Business/blob/master/05-Basic-DF-Operations/01-Basic-Structured-Operations.ipynb) we can either ask Spark to infer the schema or we explicitely specify it ourselves. For this example we need to specify the schema explicitely since not all the columns will be converted the way we would like to by the default option.\n\nAs a reminder, here is how we can define a schema contained of two columns, one string and one integer:\n\n```python\nfrom pyspark.sql.types import StructField, StructType, StringType, LongType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"name\", StringType(), True)\n])\n\ndf = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(\"gs/path/to/file\")\n```\n\nModify this code to load athlete_events.csv. Call this DataFrame `athlete_events`:\n\n**Note:** We have \"NA\" values in our data. This could cause issues when loading the data. To overcome this we need to let Spark know that what string is representing `null` in the data. We can use the option/parameter `nullValue` (as used in the sample code above) and set it to \"NA\"."}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "from pyspark.sql.types import StructField, StructType, StringType, LongType, IntegerType\n\nmyManualSchema = StructType([\n  StructField(\"ID\", LongType(), True),\n  StructField(\"Name\", StringType(), True),\n  StructField(\"Sex\", StringType(), True),\n  StructField(\"Age\", LongType(), True),\n  StructField(\"Height\", LongType(), True),\n  StructField(\"Weight\", LongType(), True),\n  StructField(\"Team\", StringType(), True),\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Games\", StringType(), True),\n  StructField(\"Year\", LongType(), True),\n  StructField(\"Season\", StringType(), True),\n  StructField(\"City\", StringType(), True),\n  StructField(\"Sport\", StringType(), True),\n  StructField(\"Event\", StringType(), True),\n  StructField(\"Medal\", StringType(), True)\n])"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the schema of this DataFrame:"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "271116"}, "execution_count": 4, "metadata": {}, "output_type": "execute_result"}], "source": "\n\nfrom pyspark.sql.functions import avg, col,sum,count\n\nathlete_events = spark.read.format(\"csv\")\\\n  .schema(myManualSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"inferSchema\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(data+\"athlete_events_new.csv\")\n\nathlete_events.count()"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "269729"}, "execution_count": 5, "metadata": {}, "output_type": "execute_result"}], "source": "# Ensuring there are no duplicate rows and dropping them if they are present.\n# This should print the list of the non-duplicate rows.\n\nathlete_events = athlete_events.drop_duplicates()\nathlete_events.count()"}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- ID: long (nullable = true)\n |-- Name: string (nullable = true)\n |-- Sex: string (nullable = true)\n |-- Age: long (nullable = true)\n |-- Height: long (nullable = true)\n |-- Weight: long (nullable = true)\n |-- Team: string (nullable = true)\n |-- NOC: string (nullable = true)\n |-- Games: string (nullable = true)\n |-- Year: long (nullable = true)\n |-- Season: string (nullable = true)\n |-- City: string (nullable = true)\n |-- Sport: string (nullable = true)\n |-- Event: string (nullable = true)\n |-- Medal: string (nullable = true)\n\n"}], "source": "# Your answer goes here\nathlete_events.printSchema()"}, {"cell_type": "markdown", "metadata": {}, "source": "Print the first 5 rows:"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "[Row(ID=167, Name='Ould Lamine Abdallah', Sex='M', Age=None, Height=None, Weight=None, Team='France', NOC='FRA', Games='1952 Summer', Year=1952, Season='Summer', City='Helsinki', Sport='Athletics', Event=\"Athletics Men's 10,000 metres\", Medal=None),\n Row(ID=181, Name='Sara Abdel Gawad', Sex='F', Age=18, Height=153, Weight=46, Team='Egypt', NOC='EGY', Games='2000 Summer', Year=2000, Season='Summer', City='Sydney', Sport='Synchronized Swimming', Event=\"Synchronized Swimming Women's Duet\", Medal=None),\n Row(ID=317, Name='Roosevelt M. Abdulgafur', Sex='M', Age=24, Height=181, Weight=73, Team='Philippines', NOC='PHI', Games='1968 Summer', Year=1968, Season='Summer', City='Mexico City', Sport='Swimming', Event=\"Swimming Men's 200 metres Freestyle\", Medal=None),\n Row(ID=519, Name='Harold Maurice Abrahams', Sex='M', Age=24, Height=183, Weight=75, Team='Great Britain', NOC='GBR', Games='1924 Summer', Year=1924, Season='Summer', City='Paris', Sport='Athletics', Event=\"Athletics Men's 200 metres\", Medal=None),\n Row(ID=604, Name='\"Folashade \"\"Shade\"\" Abugan\"', Sex='F', Age=17, Height=150, Weight=64, Team='Nigeria', NOC='NGR', Games='2008 Summer', Year=2008, Season='Summer', City='Beijing', Sport='Athletics', Event=\"Athletics Women's 400 metres\", Medal=None)]"}, "execution_count": 7, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.head(5)"}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [{"data": {"text/plain": "['ID',\n 'Name',\n 'Sex',\n 'Age',\n 'Height',\n 'Weight',\n 'Team',\n 'NOC',\n 'Games',\n 'Year',\n 'Season',\n 'City',\n 'Sport',\n 'Event',\n 'Medal']"}, "execution_count": 8, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.columns"}, {"cell_type": "markdown", "metadata": {}, "source": "We won't use the following columns, let's drop them from the DataFrame in a persistent way:\n\n* ID\n* Games\n* Event"}, {"cell_type": "code", "execution_count": 23, "metadata": {}, "outputs": [], "source": "# Creating a copy of the original file as new_athlete_events\n\nnew_athlete_events = athlete_events.select('*')\nathlete_events = athlete_events.drop(\"ID\",\"Games\",\"Event\")"}, {"cell_type": "code", "execution_count": 11, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 18:=============================>                            (1 + 1) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+--------------------+---+----+------+------+-------------+---+-----------+----+------+-----------+--------------------+--------------------+-----+\n| ID|                Name|Sex| Age|Height|Weight|         Team|NOC|      Games|Year|Season|       City|               Sport|               Event|Medal|\n+---+--------------------+---+----+------+------+-------------+---+-----------+----+------+-----------+--------------------+--------------------+-----+\n|167|Ould Lamine Abdallah|  M|null|  null|  null|       France|FRA|1952 Summer|1952|Summer|   Helsinki|           Athletics|Athletics Men's 1...| null|\n|181|    Sara Abdel Gawad|  F|  18|   153|    46|        Egypt|EGY|2000 Summer|2000|Summer|     Sydney|Synchronized Swim...|Synchronized Swim...| null|\n|317|Roosevelt M. Abdu...|  M|  24|   181|    73|  Philippines|PHI|1968 Summer|1968|Summer|Mexico City|            Swimming|Swimming Men's 20...| null|\n|519|Harold Maurice Ab...|  M|  24|   183|    75|Great Britain|GBR|1924 Summer|1924|Summer|      Paris|           Athletics|Athletics Men's 2...| null|\n|604|\"Folashade \"\"Shad...|  F|  17|   150|    64|      Nigeria|NGR|2008 Summer|2008|Summer|    Beijing|           Athletics|Athletics Women's...| null|\n+---+--------------------+---+----+------+------+-------------+---+-----------+----+------+-----------+--------------------+--------------------+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "athlete_events.show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": " Now load noc_regions.csv. Call this DataFrame `noc_regions`:"}, {"cell_type": "code", "execution_count": 12, "metadata": {}, "outputs": [], "source": "regionSchema = StructType([\n  StructField(\"NOC\", StringType(), True),\n  StructField(\"Region\", StringType(), True),\n  StructField(\"Notes\", StringType(), True)\n])\n\nnoc_regions = spark.read.format(\"csv\")\\\n  .schema(regionSchema)\\\n  .option(\"header\", \"true\")\\\n  .option(\"nullValue\", \"NA\")\\\n  .load(data + \"noc_regions.csv\")\n"}, {"cell_type": "code", "execution_count": 13, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---+-----------+--------------------+\n|NOC|     Region|               Notes|\n+---+-----------+--------------------+\n|AFG|Afghanistan|                null|\n|AHO|    Curacao|Netherlands Antilles|\n|ALB|    Albania|                null|\n|ALG|    Algeria|                null|\n|AND|    Andorra|                null|\n|ANG|     Angola|                null|\n|ANT|    Antigua| Antigua and Barbuda|\n|ANZ|  Australia|         Australasia|\n+---+-----------+--------------------+\nonly showing top 8 rows\n\n"}], "source": "noc_regions.show(8)"}, {"cell_type": "markdown", "metadata": {}, "source": "### Caching\n\nSince we will be using these two DataFrames a lot in this notebook let's `cache()` them to speed up our execution. Caching allows the DataFrame to be loaded and persist in the memory. If we don't use this option, every time we execute an action our DataFrame gets loaded from our Cloud Storage, which is not ideal and will add to our execution time:\n\n**Note:** Caching is a lazy transformation. It will happen the first time you execute an action against the DataFrame, not when you cache that DataFrame."}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[ID: bigint, Name: string, Sex: string, Age: bigint, Height: bigint, Weight: bigint, Team: string, NOC: string, Games: string, Year: bigint, Season: string, City: string, Sport: string, Event: string, Medal: string]"}, "execution_count": 14, "metadata": {}, "output_type": "execute_result"}], "source": "athlete_events.cache()"}, {"cell_type": "code", "execution_count": 15, "metadata": {}, "outputs": [{"data": {"text/plain": "DataFrame[NOC: string, Region: string, Notes: string]"}, "execution_count": 15, "metadata": {}, "output_type": "execute_result"}], "source": "noc_regions.cache()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 1\n\nWhat is the minimum and maximum `year`?"}, {"cell_type": "code", "execution_count": 14, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 6:=============================>                             (2 + 2) / 4]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+---------+\n|min(Year)|max(Year)|\n+---------+---------+\n|     1896|     2016|\n+---------+---------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Select the year column and calling min and max over the year.\n\nfrom pyspark.sql.functions import min, max\nathlete_events.select(min(\"Year\"), max(\"Year\")).show()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 2\n\nIs the following statement True or False?\n\n> Averag age of female athletes who attended the olympic games after 1990 has raised when compared to the era before then."}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": 16, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------------+\n|avg_female_age_before_1990|\n+--------------------------+\n|         21.92261478475372|\n+--------------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 28:====================================================> (194 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-------------------------+\n|avg_female_age_after_1990|\n+-------------------------+\n|       24.619499568593614|\n+-------------------------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "from pyspark.sql.functions import avg, col\n\nathlete_events.where(athlete_events[\"Sex\"] == \"F\").where(\"Year < 1990\")\\\n  .select(avg(col(\"Age\")).alias(\"avg_female_age_before_1990\")).show()\n\nathlete_events.where(athlete_events[\"Sex\"] == \"F\").where(\"Year >= 1990\")\\\n  .select(avg(col(\"Age\")).alias(\"avg_female_age_after_1990\")).show()"}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "True\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 3\n\nHow many Gold medals were given to men from 1970 to 2000 (including both years)?"}, {"cell_type": "code", "execution_count": 18, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "3186"}, "execution_count": 18, "metadata": {}, "output_type": "execute_result"}], "source": "from pyspark.sql.functions import sum, count\n\n\n#athlete_events\\\n#    .where(athlete_events[\"sex\"] == \"M\")\\\n#    .where(col(\"year\") >= 1970)\\\n#    .where(col(\"year\") <= 2000)\\\n#    .where(col(\"medal\") == \"Gold\")\\\n#    .count()\n\nathlete_events\\\n    .where(athlete_events[\"Year\"].between(1970,2000))\\\n    .where(col(\"Medal\") == \"Gold\")\\\n    .where(athlete_events[\"Sex\"] == \"M\")\\\n    .count()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 4\n\nHow many NOCs attended Summer Olympics 2016 in Rio de Janeiro?\n\nNOC stands for National Olympic Committee. Almost equivalent to a country."}, {"cell_type": "code", "execution_count": 19, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"data": {"text/plain": "207"}, "execution_count": 19, "metadata": {}, "output_type": "execute_result"}], "source": "# Your answer goes here\n\n# Your answer goes here\n#athlete_events\\\n#    .where(col(\"year\") == 2016)\\\n#    .where(col(\"Season\") == \"Summer\")\\\n#    .select(\"NOC\").distinct().count()\n\nathlete_events\\\n    .where(col(\"Games\") == \"2016 Summer\")\\\n    .select(\"NOC\").distinct().count()"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 5\n\nCreate two DataFrames, one for the Winter games and one for the Summer games; these DataFrames should include a list of all NOCs that have wone gold medals in the colympics, and their count. Sort these DataFrame by the count in a descending order. Call these DataFrames `winter_gold_count` and `summer_gold_count` respectively. Using these two, answer the following questions:\n\nWhich country has the highest gold medal count in the Winter Olympics? How about the Summer Olympics?"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Here a bit of preprocessing of the data is required before we go to actual data.\n# In olympic games, for team events when a country wins a gold medal, 'ALL' atheletes get gold medal.\n# The database shows that all atheletes get a gold medal for example in 4x100m relay race.\n# In this case, the country they represent gets a SINGLE gold, we need to remove duplicate\n# rows where country, team, sports, season and year are same so that there is single row \n# representing the country gold."}, {"cell_type": "code", "execution_count": 24, "metadata": {}, "outputs": [], "source": "from pyspark.sql.functions import regexp_replace\n\ncountry_medals = new_athlete_events\\\n    .drop_duplicates(subset= ['Team','NOC','Year','Season','City','Sport','Event','Medal'])"}, {"cell_type": "code", "execution_count": 25, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 60:>                                                         (0 + 2) / 2]\r"}, {"name": "stdout", "output_type": "stream", "text": "125152\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "print(country_medals.count())"}, {"cell_type": "code", "execution_count": 27, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Count of Gold Medals for top 5 NOC's in SUMMER Olympics:\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|USA| 2376|\n|URS|  832|\n|GBR|  634|\n|GER|  591|\n|ITA|  518|\n+---+-----+\nonly showing top 5 rows\n\nCount of Gold Medals for top 5 NOC's in WINTER Olympics:\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 81:===================================================>  (192 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|CAN|  305|\n|URS|  249|\n|USA|  159|\n|GER|  153|\n|NOR|  151|\n+---+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Your answer goes here\nfrom pyspark.sql.functions import desc, col, expr, desc\n\nsummer_gold_count = athlete_events.select(\"NOC\")\\\n    .where(col(\"Season\") == \"Summer\")\\\n    .where(col(\"Medal\") == \"Gold\")\n\nwinter_gold_count = athlete_events\\\n    .select(\"NOC\").where(col(\"Season\") == \"Winter\")\\\n    .where(col(\"Medal\") == \"Gold\")\n\nprint(\"Count of Gold Medals for top 5 NOC's in SUMMER Olympics:\")\nsummer_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(5)\n\nprint(\"Count of Gold Medals for top 5 NOC's in WINTER Olympics:\")\nwinter_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Winter_Gold_Count\")\\\n    .sort(col(\"Winter_Gold_Count.count\").desc())\\\n    .show(5)"}, {"cell_type": "code", "execution_count": 28, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 86:====================================================> (195 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|USA| 1001|\n|URS|  394|\n|GBR|  277|\n|GER|  234|\n|FRA|  234|\n+---+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 95:====================================================> (193 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---+-----+\n|NOC|count|\n+---+-----+\n|NOR|  111|\n|USA|   95|\n|GER|   86|\n|URS|   77|\n|CAN|   62|\n+---+-----+\nonly showing top 5 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# ALTERNATE CODE\n\n# Ideally speaking Canada is NOT country with highest gold medal in winter olympics\n# Because ice-hockey can have like on average 12-16 players and Canada has won it almost 12 times.\n# This makes Canada's count to swell abnormally where it should have just like 12 gold medals.\n# Wiki too shows that NORWAY has won highest gold medals in Winter olympics.\n# https://en.wikipedia.org/wiki/Winter_Olympic_Games\n\nnew_summer_gold_count = country_medals.select(\"NOC\").where(col(\"Season\") == \"Summer\").where(col(\"Medal\") == \"Gold\")\n\nnew_winter_gold_count = country_medals.select(\"NOC\").where(col(\"Season\") == \"Winter\").where(col(\"Medal\") == \"Gold\")\n\nnew_summer_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(5)\n\nnew_winter_gold_count\\\n    .groupby(\"NOC\")\\\n    .count().alias(\"Winter_Gold_Count\")\\\n    .sort(col(\"Winter_Gold_Count.count\").desc())\\\n    .show(5)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Question 6\n\nUsing the common field `NOC`, merge `summer_gold_count` and `noc_regions` DataFrames.\n\nWhich region takes the 10th place? This is based on the number of gold medals in all of the Summer Olympics in our dataset."}, {"cell_type": "code", "execution_count": 29, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Based on NOCs:\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 105:===================================================> (196 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+---------+-----+\n|   Region|count|\n+---------+-----+\n|      USA| 2376|\n|   Russia| 1220|\n|  Germany| 1074|\n|       UK|  634|\n|    Italy|  518|\n|   France|  463|\n|  Hungary|  432|\n|Australia|  362|\n|   Sweden|  352|\n|    China|  335|\n+---------+-----+\nonly showing top 10 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Your answer goes here\n\nprint(\"Based on NOCs:\")\nsummer_gold_count\\\n    .join(noc_regions, on=\"NOC\")\\\n    .groupby(\"Region\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(10)"}, {"cell_type": "code", "execution_count": 31, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Based on unique game EVENTs and NOCs:\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 111:===================================================> (196 + 2) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------+-----+\n|        Region|count|\n+--------------+-----+\n|           USA| 1001|\n|        Russia|  592|\n|       Germany|  443|\n|            UK|  277|\n|        France|  234|\n|         China|  228|\n|         Italy|  219|\n|       Hungary|  178|\n|     Australia|  150|\n|        Sweden|  149|\n|         Japan|  142|\n|       Finland|  104|\n|   South Korea|   90|\n|       Romania|   88|\n|   Netherlands|   85|\n|          Cuba|   77|\n|        Poland|   69|\n|        Canada|   64|\n|Czech Republic|   64|\n|        Norway|   59|\n+--------------+-----+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "\nprint(\"Based on unique game EVENTs and NOCs:\")\nnew_summer_gold_count\\\n    .join(noc_regions, on=\"NOC\")\\\n    .groupby(\"Region\")\\\n    .count().alias(\"Count\")\\\n    .sort(col(\"Count\").desc())\\\n    .show(20)"}, {"cell_type": "code", "execution_count": 32, "metadata": {}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+--------------------+\n|               Medal|\n+--------------------+\n|Figure Skating Mi...|\n|                null|\n|Swimming Men's 4 ...|\n|Athletics Men's 8...|\n|              Silver|\n|Swimming Women's ...|\n|                Gold|\n|Gymnastics Men's ...|\n|Fencing Men's Foi...|\n|              Bronze|\n|Cross Country Ski...|\n|Wrestling Men's H...|\n|Sailing Mixed 6 m...|\n|Athletics Women's...|\n|Fencing Men's Sab...|\n|Sailing Mixed Thr...|\n|   Rugby Men's Rugby|\n|Athletics Women's...|\n|Water Polo Men's ...|\n|Boxing Men's Welt...|\n+--------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "[Stage 125:====================================================>(199 + 1) / 200]\r"}, {"name": "stdout", "output_type": "stream", "text": "Incorrect entries: 220\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# NOTE TO PROFESSOR:\n\n# Database has entries with Name containing double-quotes and commas which skews off the entries in column.\n# This will kind of skew off the number of entries for number of gold medals after top-5.\n# \nathlete_events\\\n    .select(\"Medal\").distinct().show(20)\n\nprint(\"Incorrect entries:\",athlete_events\\\n    .select(\"Medal\").distinct().count())"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.10.8"}}, "nbformat": 4, "nbformat_minor": 4}